{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "seed= 42\n",
    "np.random.seed( seed )\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "# utility\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "from IPython.display import display\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import typing\n",
    "import pickle\n",
    "\n",
    "# visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# NLP\n",
    "import gensim\n",
    "\n",
    "# modelling and data\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "## NN\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, Bidirectional, TimeDistributed\n",
    "from tensorflow.keras.layers import Input, Flatten, Conv1D, MaxPooling1D, concatenate\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv3D, MaxPooling3D\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "# multiprocessing\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a better model than baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try\n",
    "\n",
    "1. an stacked LSTM model\n",
    "\n",
    "2. bidirectional LSTM \n",
    "\n",
    "3. CNN model\n",
    "\n",
    "4. stacking of all machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preparation for the LSTM model:\n",
    "\n",
    "Because LSTM model is a sequence learning model, we cannot featurize our data as we did for the baseline models. We need to model our input data as a sequence problem.\n",
    "\n",
    "Here for every document, we have a sequence of letters. These letters need to be integer encoded before we use them. After integer encoding them, they are passed through an embedding layer.\n",
    "\n",
    "For LSTMs, the shape of input must be in the form of **[samples, timesteps, features]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenizer(corpus: typing.List[str]\n",
    "                     ) -> Tokenizer:\n",
    "    \n",
    "    \"\"\"\n",
    "    - It takes the corpus to train a tokenizer on. \n",
    "        Usually we fit the tokenizer on the train data\n",
    "    - It returns the tokenizer object\n",
    "    \"\"\"\n",
    "    # if there will be an oov token, it will be assigned 0\n",
    "    # we can also determine oov_token by setting oov_token= max_length+1\n",
    "    tokenizer = Tokenizer(char_level=True) \n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    return tokenizer\n",
    "\n",
    "def encode_text(tokenizer: Tokenizer, \n",
    "                corpus: typing.List[ typing.List[str]],\n",
    "                max_len: int) -> np.array:\n",
    "    # character tokenize the documents\n",
    "    encoded= tokenizer.texts_to_sequences(corpus)\n",
    "    padded= sequence.pad_sequences(encoded, maxlen= max_len)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_LSTM(timesteps: int, \n",
    "                 output_size: int,\n",
    "                 vocab_size: int) -> Sequential:\n",
    "    \"\"\"\n",
    "    - timesteps: The length of the sequence\n",
    "    - output_size: It's a multiclass classification problem\n",
    "    - vocab_size: Total number of words (or letters in our case)\n",
    "    \n",
    "    It returns a sequential model\n",
    "    \"\"\"\n",
    "    kernel= 'normal'\n",
    "    embedding_size= 4\n",
    "        \n",
    "    model= Sequential(name= 'sequential')\n",
    "    model.add(Embedding(input_dim= vocab_size,\n",
    "                        output_dim= embedding_size,\n",
    "                        input_length= timesteps,\n",
    "                        name= 'embedding'))\n",
    "    #model.add( SpatialDropout1D(0.3) )\n",
    "    model.add( LSTM(200, return_sequences= True, name='LSTM_1'))\n",
    "    model.add( LSTM(200, name='LSTM_2'))\n",
    "    #model.add( LSTM(200, name='LSTM_3'))\n",
    "    model.add( Dense(500, activation= 'relu', kernel_initializer= kernel, name= 'dense_1'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add( Dense(250, activation= 'relu', kernel_initializer= kernel, name= 'dense_2'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add( Dense(100, activation= 'relu', kernel_initializer= kernel, name= 'dense_3'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add( Dense(y_train.shape[1], activation= 'softmax', kernel_initializer= kernel, name= 'dense_4'))\n",
    "    \n",
    "    model.compile(loss= 'categorical_crossentropy', optimizer= 'adam', metrics= ['accuracy'])\n",
    "    plot_model(model, show_shapes= True, to_file= 'stacked_LSTM.png')\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidirectional_LSTM(timesteps: int, \n",
    "                       output_size: int,\n",
    "                       vocab_size: int) -> Sequential:\n",
    "    kernel= 'normal'\n",
    "    embedding_size= 4\n",
    "\n",
    "    model= Sequential(name='sequential')\n",
    "    model.add(Embedding(input_dim= vocab_size,\n",
    "                        output_dim= embedding_size,\n",
    "                        input_length= timesteps,\n",
    "                        name= 'embedding'))\n",
    "    model.add( Bidirectional(LSTM(200, \n",
    "                                  dropout=0.3, \n",
    "                                  recurrent_dropout=0.3,\n",
    "                                  name= 'LSTM_1'),\n",
    "                            name= 'bidirectional') )\n",
    "    model.add( Dense(500, activation= 'relu', kernel_initializer= kernel, name= 'dense_1'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add( Dense(250, activation= 'relu', kernel_initializer= kernel, name= 'dense_2'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add( Dense(100, activation= 'relu', kernel_initializer= kernel, name= 'dense_3'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add( Dense(y_train.shape[1], activation= 'softmax', kernel_initializer= kernel, name= 'dense_4'))\n",
    "    \n",
    "    model.compile(loss= 'categorical_crossentropy', optimizer= 'adam', metrics= ['accuracy'])\n",
    "    plot_model(model, show_shapes= True, to_file= 'bidirectional_LSTM.png')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model(timesteps: int, \n",
    "              vocab_size: int) -> Model:\n",
    "    \"\"\"\n",
    "    We use a multi-channel CNN model to do the text classification wherein each chanel, we use \n",
    "    a certain filter size\n",
    "    \"\"\"\n",
    "    embedding_size= 4\n",
    "    \n",
    "    # the multichannel part\n",
    "    inputs= list()\n",
    "    flats= list()\n",
    "    \n",
    "    for i, ks in enumerate([4, 6, 8, 10, 12]):\n",
    "        input_= Input(shape= (timesteps, 1), name= f'input_{i}')\n",
    "        embedding= Embedding(vocab_size, embedding_size, name= f'embedding_{i}') (input_)\n",
    "        \n",
    "        conv_one= Conv2D(filters= 256, kernel_size= (ks, embedding_size),\n",
    "                         padding= 'same', activation= 'relu', name= f'conv_one_{i}')(embedding)\n",
    "        drop_one= Dropout(0.5, name= f'dropout_one_{i}')(conv_one)\n",
    "        pool_one= MaxPooling2D( pool_size= (timesteps-ks+1, 1), name= f'pooling_one_{i}')(drop_one)\n",
    "        \n",
    "        #conv_two= Conv2D(filters= 128, kernel_size= (ks, embedding_size), \n",
    "        #                 padding= 'same', activation= 'relu', name= f'conv_two_{i}')(pool_one)\n",
    "        #drop_two= Dropout(0.5, name= f'dropout_two_{i}')(conv_two)\n",
    "        \n",
    "        flat= Flatten(name= f'flatten_{i}')(pool_one)\n",
    "        \n",
    "        inputs.append(input_)\n",
    "        flats.append(flat)\n",
    "        \n",
    "    merged= concatenate(flats, name= 'merged')\n",
    "    # The dense layers part\n",
    "    dense1= Dense(512, activation= 'relu', name= 'dense_1')(merged)\n",
    "    drop1= Dropout(0.5, name= 'dropout_1')(dense1)\n",
    "    dense2= Dense(256, activation= 'relu', name= 'dense_2')(drop1)\n",
    "    drop2= Dropout(0.5, name= 'dropout_2')(dense2)\n",
    "    dense3= Dense(y_train.shape[1], activation= 'softmax', name= 'dense_3') (drop2)\n",
    "    \n",
    "    # build the model\n",
    "    model= Model(inputs= inputs, outputs= dense3)\n",
    "    \n",
    "    # compile\n",
    "    model.compile(loss= 'categorical_crossentropy', optimizer= 'adam', metrics= ['accuracy'])\n",
    "    \n",
    "    #model.sumamry()\n",
    "    plot_model(model, show_shapes= True, to_file= 'multichannel_cnn.png')\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (32513, 452, 1)\n",
      "y_train shape:  (32513, 12)\n",
      "X_test shape:  (3000, 452)\n"
     ]
    }
   ],
   "source": [
    "path= os.path.join('/kaggle', 'input', 'obfuscated_text', 'xtrain_obfuscated.txt')\n",
    "xtrain= pd.read_csv(path, header= None)\n",
    "xtrain.columns= ['text']\n",
    "\n",
    "path= os.path.join('/kaggle', 'input', 'obfuscated_text', 'xtest_obfuscated.txt')\n",
    "xtest= pd.read_csv(path, header= None)\n",
    "xtest.columns= ['text']\n",
    "\n",
    "path= os.path.join('/kaggle', 'input', 'obfuscated_text', 'ytrain.txt')\n",
    "ytrain= pd.read_csv(path, header= None)\n",
    "ytrain.columns= ['label']\n",
    "\n",
    "data= pd.concat([xtrain, ytrain], axis= 1)\n",
    "data= pd.concat([data, xtest], axis= 0)\n",
    "data['length']= data['text'].apply(len)\n",
    "\n",
    "#####################################   data    #####################################\n",
    "tokenizer= create_tokenizer(corpus= xtrain['text'].tolist())\n",
    "X_train= encode_text(tokenizer,\n",
    "                 corpus= [list(el) for el in xtrain['text'].tolist()],\n",
    "                 max_len= data['length'].max())\n",
    "X_train= X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "\n",
    "X_test= encode_text(tokenizer,\n",
    "                 corpus= [list(el) for el in xtest['text'].tolist()],\n",
    "                 max_len= data['length'].max())\n",
    "\n",
    "y_train= utils.to_categorical(ytrain)\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_test shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create validation data from X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tr shape:  (26010, 452, 1)\n",
      "y_tr shape:  (26010, 12)\n",
      "X_val shape:  (6503, 452, 1)\n",
      "y_val shape:  (6503, 12)\n"
     ]
    }
   ],
   "source": [
    "X_tr, X_val, y_tr, y_val= train_test_split(X_train, \n",
    "                                           y_train, \n",
    "                                           test_size= 0.2,\n",
    "                                           random_state= seed,\n",
    "                                           stratify= ytrain.values)\n",
    "print('X_tr shape: ', X_tr.shape)\n",
    "print('y_tr shape: ', y_tr.shape)\n",
    "print('X_val shape: ', X_val.shape)\n",
    "print('y_val shape: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPU initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect and init the TPU\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "# instantiate a distribution strategy\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dl_model(model: typing.Any, \n",
    "                  model_path: str,\n",
    "                  model_weights_path: str) -> None:\n",
    "    \"\"\"\n",
    "    It saves a deep learning model to given pathes. \n",
    "    model can either be sequential or keras Model class\n",
    "    \"\"\"\n",
    "    model_json = model.to_json()\n",
    "    with open(model_path, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights( model_weights_path )\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_pickle(var: typing.Any, \n",
    "                 path: str) -> None:\n",
    "    \"\"\"\n",
    "    Writes variable var to path.\n",
    "    \"\"\"\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(var, f, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes= np.unique(ytrain['label'])\n",
    "#class_weights= list( class_weight.compute_class_weight('balanced', \n",
    "#                                                        classes,\n",
    "#                                                        ytrain['label'].values) )\n",
    "#class_weights= {k: class_weights[i] for i, k in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stacked_LSTM = True\n",
    "train_bidirectional_LSTM = False\n",
    "train_multichannel_CNN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "407/407 [==============================] - 17s 42ms/step - accuracy: 0.2048 - loss: 2.2228 - val_accuracy: 0.2931 - val_loss: 2.0234\n",
      "Epoch 2/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.4241 - loss: 1.6718 - val_accuracy: 0.5319 - val_loss: 1.3490\n",
      "Epoch 3/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.5597 - loss: 1.2641 - val_accuracy: 0.6023 - val_loss: 1.1650\n",
      "Epoch 4/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.6146 - loss: 1.1132 - val_accuracy: 0.6598 - val_loss: 1.0081\n",
      "Epoch 5/70\n",
      "407/407 [==============================] - 10s 24ms/step - accuracy: 0.6474 - loss: 1.0271 - val_accuracy: 0.7092 - val_loss: 0.9059\n",
      "Epoch 6/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.6756 - loss: 0.9553 - val_accuracy: 0.7392 - val_loss: 0.8318\n",
      "Epoch 7/70\n",
      "407/407 [==============================] - 9s 22ms/step - accuracy: 0.7068 - loss: 0.8803 - val_accuracy: 0.7403 - val_loss: 0.8008\n",
      "Epoch 8/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.7202 - loss: 0.8346 - val_accuracy: 0.7552 - val_loss: 0.7710\n",
      "Epoch 9/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.7287 - loss: 0.8050 - val_accuracy: 0.7726 - val_loss: 0.7179\n",
      "Epoch 10/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.7374 - loss: 0.7773 - val_accuracy: 0.7686 - val_loss: 0.7193\n",
      "Epoch 11/70\n",
      "407/407 [==============================] - 10s 23ms/step - accuracy: 0.7493 - loss: 0.7455 - val_accuracy: 0.7761 - val_loss: 0.6911\n",
      "Epoch 12/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.7579 - loss: 0.7283 - val_accuracy: 0.7864 - val_loss: 0.6566\n",
      "Epoch 13/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.7598 - loss: 0.7090 - val_accuracy: 0.8009 - val_loss: 0.6188\n",
      "Epoch 14/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.7702 - loss: 0.6890 - val_accuracy: 0.7938 - val_loss: 0.6273\n",
      "Epoch 15/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.7708 - loss: 0.6782 - val_accuracy: 0.7927 - val_loss: 0.6200\n",
      "Epoch 16/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.7772 - loss: 0.6630 - val_accuracy: 0.7981 - val_loss: 0.6165\n",
      "Epoch 17/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.7819 - loss: 0.6504 - val_accuracy: 0.8038 - val_loss: 0.5961\n",
      "Epoch 18/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.7844 - loss: 0.6428 - val_accuracy: 0.8061 - val_loss: 0.5984\n",
      "Epoch 19/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.7933 - loss: 0.6196 - val_accuracy: 0.8167 - val_loss: 0.5740\n",
      "Epoch 20/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.7929 - loss: 0.6147 - val_accuracy: 0.8052 - val_loss: 0.5859\n",
      "Epoch 21/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.7973 - loss: 0.5984 - val_accuracy: 0.8164 - val_loss: 0.5709\n",
      "Epoch 22/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.7974 - loss: 0.6030 - val_accuracy: 0.8107 - val_loss: 0.5759\n",
      "Epoch 23/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.7957 - loss: 0.5962 - val_accuracy: 0.8098 - val_loss: 0.5617\n",
      "Epoch 24/70\n",
      "407/407 [==============================] - 10s 23ms/step - accuracy: 0.8029 - loss: 0.5882 - val_accuracy: 0.8176 - val_loss: 0.5572\n",
      "Epoch 25/70\n",
      "407/407 [==============================] - 10s 24ms/step - accuracy: 0.8051 - loss: 0.5802 - val_accuracy: 0.8229 - val_loss: 0.5464\n",
      "Epoch 26/70\n",
      "407/407 [==============================] - 10s 24ms/step - accuracy: 0.8093 - loss: 0.5677 - val_accuracy: 0.8253 - val_loss: 0.5391\n",
      "Epoch 27/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8121 - loss: 0.5627 - val_accuracy: 0.8132 - val_loss: 0.5438\n",
      "Epoch 28/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8126 - loss: 0.5526 - val_accuracy: 0.8218 - val_loss: 0.5438\n",
      "Epoch 29/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8127 - loss: 0.5518 - val_accuracy: 0.8215 - val_loss: 0.5480\n",
      "Epoch 30/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8148 - loss: 0.5458 - val_accuracy: 0.8221 - val_loss: 0.5335\n",
      "Epoch 31/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8188 - loss: 0.5434 - val_accuracy: 0.8241 - val_loss: 0.5301\n",
      "Epoch 32/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8165 - loss: 0.5411 - val_accuracy: 0.8261 - val_loss: 0.5333\n",
      "Epoch 33/70\n",
      "407/407 [==============================] - 10s 24ms/step - accuracy: 0.8181 - loss: 0.5330 - val_accuracy: 0.8281 - val_loss: 0.5153\n",
      "Epoch 34/70\n",
      "407/407 [==============================] - 10s 23ms/step - accuracy: 0.8230 - loss: 0.5265 - val_accuracy: 0.8281 - val_loss: 0.5223\n",
      "Epoch 35/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8217 - loss: 0.5279 - val_accuracy: 0.8258 - val_loss: 0.5313\n",
      "Epoch 36/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8262 - loss: 0.5155 - val_accuracy: 0.8204 - val_loss: 0.5438\n",
      "Epoch 37/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8254 - loss: 0.5209 - val_accuracy: 0.8242 - val_loss: 0.5312\n",
      "Epoch 38/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8275 - loss: 0.5072 - val_accuracy: 0.8344 - val_loss: 0.5047\n",
      "Epoch 39/70\n",
      "407/407 [==============================] - 10s 23ms/step - accuracy: 0.8285 - loss: 0.5069 - val_accuracy: 0.8272 - val_loss: 0.5206\n",
      "Epoch 40/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8323 - loss: 0.4964 - val_accuracy: 0.8293 - val_loss: 0.5065\n",
      "Epoch 41/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8325 - loss: 0.4960 - val_accuracy: 0.8359 - val_loss: 0.4972\n",
      "Epoch 42/70\n",
      "407/407 [==============================] - 10s 25ms/step - accuracy: 0.8304 - loss: 0.4946 - val_accuracy: 0.8272 - val_loss: 0.5120\n",
      "Epoch 43/70\n",
      "407/407 [==============================] - 9s 22ms/step - accuracy: 0.8349 - loss: 0.4850 - val_accuracy: 0.8305 - val_loss: 0.4986\n",
      "Epoch 44/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8336 - loss: 0.4908 - val_accuracy: 0.8302 - val_loss: 0.5051\n",
      "Epoch 45/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8360 - loss: 0.4814 - val_accuracy: 0.8367 - val_loss: 0.5089\n",
      "Epoch 46/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8380 - loss: 0.4759 - val_accuracy: 0.8319 - val_loss: 0.5017\n",
      "Epoch 47/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8364 - loss: 0.4712 - val_accuracy: 0.8353 - val_loss: 0.4923\n",
      "Epoch 48/70\n",
      "407/407 [==============================] - 10s 23ms/step - accuracy: 0.8385 - loss: 0.4743 - val_accuracy: 0.8299 - val_loss: 0.5002\n",
      "Epoch 49/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8398 - loss: 0.4746 - val_accuracy: 0.8321 - val_loss: 0.4991\n",
      "Epoch 50/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8386 - loss: 0.4775 - val_accuracy: 0.8332 - val_loss: 0.4970\n",
      "Epoch 51/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8399 - loss: 0.4708 - val_accuracy: 0.8398 - val_loss: 0.4926\n",
      "Epoch 52/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8409 - loss: 0.4667 - val_accuracy: 0.8315 - val_loss: 0.5148\n",
      "Epoch 53/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8433 - loss: 0.4614 - val_accuracy: 0.8315 - val_loss: 0.4965\n",
      "Epoch 54/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8448 - loss: 0.4516 - val_accuracy: 0.8430 - val_loss: 0.4869\n",
      "Epoch 55/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8437 - loss: 0.4586 - val_accuracy: 0.8427 - val_loss: 0.4858\n",
      "Epoch 56/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8421 - loss: 0.4645 - val_accuracy: 0.8376 - val_loss: 0.4897\n",
      "Epoch 57/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8439 - loss: 0.4543 - val_accuracy: 0.8332 - val_loss: 0.5022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/70\n",
      "407/407 [==============================] - 10s 24ms/step - accuracy: 0.8497 - loss: 0.4434 - val_accuracy: 0.8335 - val_loss: 0.4956\n",
      "Epoch 59/70\n",
      "407/407 [==============================] - 10s 25ms/step - accuracy: 0.8467 - loss: 0.4464 - val_accuracy: 0.8445 - val_loss: 0.4744\n",
      "Epoch 60/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8500 - loss: 0.4424 - val_accuracy: 0.8385 - val_loss: 0.4838\n",
      "Epoch 61/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8482 - loss: 0.4398 - val_accuracy: 0.8335 - val_loss: 0.4893\n",
      "Epoch 62/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8492 - loss: 0.4423 - val_accuracy: 0.8495 - val_loss: 0.4723\n",
      "Epoch 63/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8531 - loss: 0.4344 - val_accuracy: 0.8356 - val_loss: 0.4898\n",
      "Epoch 64/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8504 - loss: 0.4384 - val_accuracy: 0.8427 - val_loss: 0.4747\n",
      "Epoch 65/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8546 - loss: 0.4293 - val_accuracy: 0.8355 - val_loss: 0.4855\n",
      "Epoch 66/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8505 - loss: 0.4354 - val_accuracy: 0.8347 - val_loss: 0.4895\n",
      "Epoch 67/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8512 - loss: 0.4318 - val_accuracy: 0.8401 - val_loss: 0.4750\n",
      "Epoch 68/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8507 - loss: 0.4376 - val_accuracy: 0.8370 - val_loss: 0.4886\n",
      "Epoch 69/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8555 - loss: 0.4277 - val_accuracy: 0.8368 - val_loss: 0.4913\n",
      "Epoch 70/70\n",
      "407/407 [==============================] - 9s 23ms/step - accuracy: 0.8556 - loss: 0.4250 - val_accuracy: 0.8412 - val_loss: 0.4809\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "with tpu_strategy.scope():\n",
    "    \n",
    "    if train_stacked_LSTM:\n",
    "        # training stacked LSTM\n",
    "        model= stacked_LSTM(timesteps = X_tr.shape[1],\n",
    "                            output_size = y_tr.shape[1],\n",
    "                            vocab_size = len(tokenizer.word_index) + 1)\n",
    "        history= model.fit(X_tr, y_tr, \n",
    "                           epochs= 300, \n",
    "                           batch_size= 128, \n",
    "                           validation_data= (X_val, y_val))\n",
    "        plt.plot( history.history['accuracy'])\n",
    "        plt.plot( history.history['val_accuracy'])\n",
    "        plt.title('stacked_LSTM')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        save_dl_model(model = model,\n",
    "                      model_path = os.path.join( os.getcwd(), 'stacked_LSTM.json'),\n",
    "                      model_weights_path = os.path.join( os.getcwd(), 'stacked_LSTM.h5'))\n",
    "        # save history\n",
    "        pd.DataFrame(history.history).to_csv('stacked_LSTM_history.csv')\n",
    "    ####################################################################\n",
    "    if train_bidirectional_LSTM:\n",
    "        # training bidirectional LSTM\n",
    "        model= bidirectional_LSTM(timesteps = X_tr.shape[1],\n",
    "                                  output_size = y_tr.shape[1],\n",
    "                                  vocab_size = len(tokenizer.word_index) + 1)\n",
    "\n",
    "        history= model.fit(X_tr, y_tr, \n",
    "                           epochs= 500, \n",
    "                           batch_size= 128, \n",
    "                           validation_data= (X_val, y_val))\n",
    "        plt.plot( history.history['accuracy'])\n",
    "        plt.plot( history.history['val_accuracy'])\n",
    "        plt.title('bidirectional_LSTM')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        save_dl_model(model = model,\n",
    "                      model_path = os.path.join( os.getcwd(), 'bidirectional_LSTM.json'),\n",
    "                      model_weights_path = os.path.join( os.getcwd(), 'bidirectional_LSTM.h5'))\n",
    "        # save history\n",
    "        pd.DataFrame(history.history).to_csv('bidirectional_LSTM_history.csv')\n",
    "    ####################################################################\n",
    "    if train_multichannel_CNN:\n",
    "        num_channels= 5\n",
    "        model= CNN_model(timesteps = X_tr.shape[1],\n",
    "                         vocab_size = len(tokenizer.word_index) + 1)\n",
    "        history= model.fit( [X_tr]*num_channels, \n",
    "                            y_tr, \n",
    "                            validation_data= ([X_val]*num_channels, y_val),  \n",
    "                            epochs= 100, batch_size= 64 )\n",
    "        plt.plot( history.history['accuracy'])\n",
    "        plt.plot( history.history['val_accuracy'])\n",
    "        plt.title('multichannel_CNN')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        save_dl_model(model = model,\n",
    "                      model_path = os.path.join( os.getcwd(), 'multichannel_CNN.json'),\n",
    "                      model_weights_path = os.path.join( os.getcwd(), 'multichannel_CNN.h5'))\n",
    "        # save history\n",
    "        pd.DataFrame(history.history).to_csv('multichannel_CNN_history.csv')\n",
    "        ####### predict X_test for CNN\n",
    "        y_test_predicted = model.predict([X_test]*num_channels)\n",
    "        y_test_predicted = pd.DataFrame(np.argmax(y_test_predicted, \n",
    "                                                  axis= 1 )\n",
    "                                       , columns= ['y_test_predicted'])\n",
    "        y_test_predicted.to_csv('y_test_predicted.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
